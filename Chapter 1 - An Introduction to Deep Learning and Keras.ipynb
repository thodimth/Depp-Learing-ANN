{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Keras for Deep Neural Networks\n",
    "## Chapter 1 - An Introduction to Deep Learning and Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras: python deep learning framework built on top of TF(tensor flow).\n",
    "\n",
    "#   https://en.wikipedia.org/wiki/Keras --Link for keras(source:wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on keras:\n",
    "# Keras is an open-source neural-network library written in Python. \n",
    "It is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, R, Theano, or PlaidML.[1][2] Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible. It was developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System),[3] and its primary author and maintainer is FranÃ§ois Chollet, a Google engineer.\n",
    "Chollet also is the author of the XCeption deep neural network model\n",
    "\n",
    "->Keras contains numerous implementations of commonly used neural-network building blocks such as layers, objectives, activation functions, optimizers, and a host of tools to make working with image and text data easier to simplify the coding necessary for writing Deep Neural Network code.\n",
    "\n",
    "->In addition to standard neural networks, Keras has support for convolutional and recurrent neural networks. It supports other common utility layers like dropout, batch normalization, and pooling.[9]\n",
    "\n",
    "Keras allows users to productize deep models on smartphones (iOS and Android), on the web, or on the Java Virtual Machine.[10] It also allows use of distributed training of deep-learning models on clusters of Graphics Processing Units (GPU) and Tensor processing units (TPU) principally in conjunction with CUDA.[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow: python deep learning framework ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#notes on tensor flow:\n",
    "TensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. \n",
    "It is a symbolic math library, and is also used for machine learning applications such as neural networks.[4] \n",
    "It is used for both research and production at Google\n",
    "\n",
    "TensorFlow was developed by the Google Brain team for internal Google use. It was released under the Apache License 2.0 on November 9, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.25.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\krishna reddy\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sneak peek in the Keras Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(5, size=(1000, 1))   #generates 0,1,2,3 and 4 randomly with 1000 samples and one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88234931, 0.10432774, 0.90700933],\n",
       "       [0.3063989 , 0.44640887, 0.58998539],\n",
       "       [0.8371111 , 0.69780061, 0.80280284],\n",
       "       ...,\n",
       "       [0.76474832, 0.12224649, 0.06019634],\n",
       "       [0.21847107, 0.57064847, 0.27701246],\n",
       "       [0.97785211, 0.81210972, 0.34780075]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 3, 3],\n",
       "       [1, 1, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(5, size=(2, 4))   #learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56483978, 0.38110148],\n",
       "       [0.80550362, 0.56157338],\n",
       "       [0.01302482, 0.54218983],\n",
       "       [0.6005349 , 0.11518427],\n",
       "       [0.48182455, 0.30980366],\n",
       "       [0.40938373, 0.61209506],\n",
       "       [0.68175335, 0.53679221],\n",
       "       [0.5975519 , 0.44051974],\n",
       "       [0.60974298, 0.85996287]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((9,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27125813, -1.45463451])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.seed(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# about random: https://www.geeksforgeeks.org/random-seed-in-python/\n",
    "\n",
    "=>random.seed( ) in Python\n",
    "->random() function is used to generate random numbers in Python. Not actually random, rather this is used to generate pseudo-random numbers. That implies that these randomly generated numbers can be determined.\n",
    "\n",
    "random() function generates numbers for some values. This value is also called seed value.\n",
    "\n",
    "How Seed Function Works ?\n",
    "Seed function is used to save the state of random function, so that it can generate some random numbers on multiple execution of the code on the same machine or on different machines (for a specific seed value). Seed value is the previous value number generated by the generator. For the first time when there is no previous value, it uses current system time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88234931, 0.10432774, 0.90700933],\n",
       "       [0.3063989 , 0.44640887, 0.58998539],\n",
       "       [0.8371111 , 0.69780061, 0.80280284],\n",
       "       ...,\n",
       "       [0.76474832, 0.12224649, 0.06019634],\n",
       "       [0.21847107, 0.57064847, 0.27701246],\n",
       "       [0.97785211, 0.81210972, 0.34780075]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()  # sequential container initialized.\n",
    "model.add(Dense(10, input_dim=3, activation='relu'))  #HIDDEN LAYER 1  #here 10 is the count of neurons and 3 is the size/number of inputs\n",
    "model.add(Dense(5, activation='relu'))  #HIDDEN LAYER 2\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # OUTPUT LAYER    #sigmid function is applied:e^x / 1+e^-x  #model.add(): Adds a layer instance on top of the layer stack.\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])   #model.compile(): Configures the model for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: -2.5972 - accuracy: 0.1960\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 0s 109us/step - loss: -3.8068 - accuracy: 0.1960\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 0s 104us/step - loss: -5.2775 - accuracy: 0.1960\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: -7.0926 - accuracy: 0.1960\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: -9.3016 - accuracy: 0.1960\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: -12.0763 - accuracy: 0.1960\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: -15.3769 - accuracy: 0.1960\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 0s 119us/step - loss: -19.3997 - accuracy: 0.1960\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: -24.2197 - accuracy: 0.1960\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: -29.7772 - accuracy: 0.1960\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: -36.2146 - accuracy: 0.1960\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 0s 106us/step - loss: -43.3578 - accuracy: 0.1960\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: -51.5009 - accuracy: 0.1960\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 0s 119us/step - loss: -60.6343 - accuracy: 0.1960\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: -70.5592 - accuracy: 0.1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x244c127ea90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=15,batch_size=32)\n",
    "\n",
    "\n",
    "# batchsize and epochs: https://www.quora.com/What-is-the-difference-between-iterations-and-epochs-in-Convolution-neural-networks\n",
    "#Epoch : It simply represents one iteration over the entire dataset\n",
    "#Batches : We split the total data into many segments or Batches\n",
    "#Iterations : Iterations are number of batches we need to compile one Epoch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " epochs: Integer. Number of epochs to train the model.\n",
    "        An epoch is an iteration over the entire `x` and `y`\n",
    "        data provided.\n",
    "        Note that in conjunction with `initial_epoch`,\n",
    "        `epochs` is to be understood as \"final epoch\".\n",
    "        The model is not trained for a number of iterations\n",
    "        given by `epochs`, but merely until the epoch\n",
    "        of index `epochs` is reached.\n",
    "        \n",
    "batch_size: Integer or `None`.\n",
    "        Number of samples per gradient update.\n",
    "        If unspecified, `batch_size` will default to 32.\n",
    "        Do not specify the `batch_size` if your data is in the\n",
    "        form of symbolic tensors, generators, or `Sequence` instances\n",
    "        (since they generate batches).     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9953595 ],\n",
       "       [0.9987051 ],\n",
       "       [0.99792886],\n",
       "       [0.99627024],\n",
       "       [0.9970968 ],\n",
       "       [0.98909295],\n",
       "       [0.9980233 ],\n",
       "       [0.9959101 ],\n",
       "       [0.9964551 ],\n",
       "       [0.99052334],\n",
       "       [0.99643886],\n",
       "       [0.9991925 ],\n",
       "       [0.99930036],\n",
       "       [0.99876153],\n",
       "       [0.99654305],\n",
       "       [0.99776095],\n",
       "       [0.99918556],\n",
       "       [0.9971235 ],\n",
       "       [0.99902844],\n",
       "       [0.9992951 ],\n",
       "       [0.99816024],\n",
       "       [0.9969245 ],\n",
       "       [0.99348265],\n",
       "       [0.99576926],\n",
       "       [0.99174964],\n",
       "       [0.99512064],\n",
       "       [0.99724984],\n",
       "       [0.993144  ],\n",
       "       [0.99925196],\n",
       "       [0.99854845],\n",
       "       [0.99624425],\n",
       "       [0.99645805],\n",
       "       [0.9953455 ],\n",
       "       [0.99821806],\n",
       "       [0.99718904],\n",
       "       [0.99508727],\n",
       "       [0.99916637],\n",
       "       [0.9982121 ],\n",
       "       [0.9959763 ],\n",
       "       [0.9926169 ],\n",
       "       [0.9996345 ],\n",
       "       [0.9994342 ],\n",
       "       [0.999683  ],\n",
       "       [0.99848324],\n",
       "       [0.99873674],\n",
       "       [0.9949044 ],\n",
       "       [0.9987017 ],\n",
       "       [0.9983636 ],\n",
       "       [0.99657106],\n",
       "       [0.9980993 ],\n",
       "       [0.9964968 ],\n",
       "       [0.995305  ],\n",
       "       [0.9957299 ],\n",
       "       [0.9931669 ],\n",
       "       [0.99178433],\n",
       "       [0.9996402 ],\n",
       "       [0.99791455],\n",
       "       [0.99909174],\n",
       "       [0.9941127 ],\n",
       "       [0.9949835 ],\n",
       "       [0.996616  ],\n",
       "       [0.9990715 ],\n",
       "       [0.9970857 ],\n",
       "       [0.99546987],\n",
       "       [0.99617606],\n",
       "       [0.9946606 ],\n",
       "       [0.9977365 ],\n",
       "       [0.9965824 ],\n",
       "       [0.9978562 ],\n",
       "       [0.99359834],\n",
       "       [0.9937917 ],\n",
       "       [0.96771455],\n",
       "       [0.9985349 ],\n",
       "       [0.997429  ],\n",
       "       [0.9969857 ],\n",
       "       [0.9986503 ],\n",
       "       [0.9990448 ],\n",
       "       [0.99522316],\n",
       "       [0.99564123],\n",
       "       [0.9978321 ],\n",
       "       [0.9941304 ],\n",
       "       [0.9983843 ],\n",
       "       [0.9992309 ],\n",
       "       [0.9953283 ],\n",
       "       [0.9946312 ],\n",
       "       [0.9979427 ],\n",
       "       [0.99943095],\n",
       "       [0.99915004],\n",
       "       [0.98589057],\n",
       "       [0.99343467],\n",
       "       [0.99212605],\n",
       "       [0.99699724],\n",
       "       [0.99860865],\n",
       "       [0.9990632 ],\n",
       "       [0.9985287 ],\n",
       "       [0.9952183 ],\n",
       "       [0.9986285 ],\n",
       "       [0.9929099 ],\n",
       "       [0.99954176],\n",
       "       [0.99969006],\n",
       "       [0.995745  ],\n",
       "       [0.9976412 ],\n",
       "       [0.9991957 ],\n",
       "       [0.99921024],\n",
       "       [0.998461  ],\n",
       "       [0.9940614 ],\n",
       "       [0.9907433 ],\n",
       "       [0.99873334],\n",
       "       [0.9990773 ],\n",
       "       [0.9955977 ],\n",
       "       [0.9931892 ],\n",
       "       [0.984143  ],\n",
       "       [0.99607944],\n",
       "       [0.99874544],\n",
       "       [0.99292636],\n",
       "       [0.9950949 ],\n",
       "       [0.998808  ],\n",
       "       [0.9994375 ],\n",
       "       [0.9933138 ],\n",
       "       [0.9919872 ],\n",
       "       [0.9997282 ],\n",
       "       [0.9953624 ],\n",
       "       [0.9979811 ],\n",
       "       [0.9931052 ],\n",
       "       [0.99942565],\n",
       "       [0.9972639 ],\n",
       "       [0.99900913],\n",
       "       [0.99327135],\n",
       "       [0.99519104],\n",
       "       [0.99731773],\n",
       "       [0.9952835 ],\n",
       "       [0.99793684],\n",
       "       [0.9979242 ],\n",
       "       [0.99855065],\n",
       "       [0.9987714 ],\n",
       "       [0.99734473],\n",
       "       [0.97828674],\n",
       "       [0.9757788 ],\n",
       "       [0.99962413],\n",
       "       [0.9984176 ],\n",
       "       [0.99648255],\n",
       "       [0.99901235],\n",
       "       [0.9955033 ],\n",
       "       [0.9929682 ],\n",
       "       [0.9981397 ],\n",
       "       [0.9981816 ],\n",
       "       [0.99462545],\n",
       "       [0.97982234],\n",
       "       [0.99444914],\n",
       "       [0.99707633],\n",
       "       [0.99224657],\n",
       "       [0.9946656 ],\n",
       "       [0.98627007],\n",
       "       [0.9950924 ],\n",
       "       [0.9943515 ],\n",
       "       [0.9962974 ],\n",
       "       [0.9952866 ],\n",
       "       [0.997342  ],\n",
       "       [0.99343276],\n",
       "       [0.9910444 ],\n",
       "       [0.99635506],\n",
       "       [0.997419  ],\n",
       "       [0.99214363],\n",
       "       [0.9990033 ],\n",
       "       [0.9974896 ],\n",
       "       [0.9984323 ],\n",
       "       [0.9862673 ],\n",
       "       [0.9981362 ],\n",
       "       [0.9890866 ],\n",
       "       [0.99227977],\n",
       "       [0.9956836 ],\n",
       "       [0.99753815],\n",
       "       [0.9992464 ],\n",
       "       [0.99727666],\n",
       "       [0.99076796],\n",
       "       [0.9989403 ],\n",
       "       [0.9981214 ],\n",
       "       [0.99642414],\n",
       "       [0.99737954],\n",
       "       [0.9913198 ],\n",
       "       [0.99843955],\n",
       "       [0.9991277 ],\n",
       "       [0.98906785],\n",
       "       [0.9978721 ],\n",
       "       [0.9982195 ],\n",
       "       [0.9994847 ],\n",
       "       [0.9890408 ],\n",
       "       [0.99773943],\n",
       "       [0.99839866],\n",
       "       [0.9884534 ],\n",
       "       [0.9987534 ],\n",
       "       [0.9966211 ],\n",
       "       [0.9898594 ],\n",
       "       [0.9992201 ],\n",
       "       [0.99834996],\n",
       "       [0.99126625],\n",
       "       [0.9964844 ],\n",
       "       [0.9985379 ],\n",
       "       [0.9985693 ],\n",
       "       [0.9931636 ],\n",
       "       [0.99194646],\n",
       "       [0.99691784],\n",
       "       [0.9993123 ],\n",
       "       [0.99755335],\n",
       "       [0.9985926 ],\n",
       "       [0.9936074 ],\n",
       "       [0.9959499 ],\n",
       "       [0.9954715 ],\n",
       "       [0.998091  ],\n",
       "       [0.99825096],\n",
       "       [0.99930096],\n",
       "       [0.9873711 ],\n",
       "       [0.9920566 ],\n",
       "       [0.9992211 ],\n",
       "       [0.99916047],\n",
       "       [0.9966636 ],\n",
       "       [0.98628056],\n",
       "       [0.99925053],\n",
       "       [0.99512404],\n",
       "       [0.9996693 ],\n",
       "       [0.9993608 ],\n",
       "       [0.9958185 ],\n",
       "       [0.99736744],\n",
       "       [0.9992129 ],\n",
       "       [0.9994345 ],\n",
       "       [0.9994284 ],\n",
       "       [0.9816079 ],\n",
       "       [0.99514335],\n",
       "       [0.996413  ],\n",
       "       [0.9925529 ],\n",
       "       [0.99706876],\n",
       "       [0.9975728 ],\n",
       "       [0.9924891 ],\n",
       "       [0.99608   ],\n",
       "       [0.99948055],\n",
       "       [0.9992478 ],\n",
       "       [0.9996108 ],\n",
       "       [0.99647725],\n",
       "       [0.9946666 ],\n",
       "       [0.9923627 ],\n",
       "       [0.99750745],\n",
       "       [0.9989824 ],\n",
       "       [0.9942738 ],\n",
       "       [0.99334395],\n",
       "       [0.9953015 ],\n",
       "       [0.98665285],\n",
       "       [0.993096  ],\n",
       "       [0.9945245 ],\n",
       "       [0.99740237],\n",
       "       [0.994016  ],\n",
       "       [0.9994726 ],\n",
       "       [0.9978101 ],\n",
       "       [0.99061334],\n",
       "       [0.9937855 ],\n",
       "       [0.99438167],\n",
       "       [0.99928296],\n",
       "       [0.9988515 ],\n",
       "       [0.99841416],\n",
       "       [0.9976938 ],\n",
       "       [0.9958914 ],\n",
       "       [0.9964659 ],\n",
       "       [0.9943    ],\n",
       "       [0.9954026 ],\n",
       "       [0.9977082 ],\n",
       "       [0.9899342 ],\n",
       "       [0.99768925],\n",
       "       [0.99586695],\n",
       "       [0.99840635],\n",
       "       [0.9863569 ],\n",
       "       [0.9863933 ],\n",
       "       [0.99856925],\n",
       "       [0.98393416],\n",
       "       [0.999699  ],\n",
       "       [0.9871392 ],\n",
       "       [0.9959077 ],\n",
       "       [0.9979035 ],\n",
       "       [0.9988922 ],\n",
       "       [0.98572826],\n",
       "       [0.9987446 ],\n",
       "       [0.9979156 ],\n",
       "       [0.9995064 ],\n",
       "       [0.9973336 ],\n",
       "       [0.99912536],\n",
       "       [0.9974413 ],\n",
       "       [0.99801946],\n",
       "       [0.99790215],\n",
       "       [0.9961818 ],\n",
       "       [0.9992543 ],\n",
       "       [0.9988561 ],\n",
       "       [0.9987058 ],\n",
       "       [0.99282944],\n",
       "       [0.9987898 ],\n",
       "       [0.9987587 ],\n",
       "       [0.9995831 ],\n",
       "       [0.99860156],\n",
       "       [0.9976091 ],\n",
       "       [0.9928968 ],\n",
       "       [0.9992095 ],\n",
       "       [0.99935293],\n",
       "       [0.99696946],\n",
       "       [0.9913552 ],\n",
       "       [0.9913968 ],\n",
       "       [0.9937675 ],\n",
       "       [0.9991914 ],\n",
       "       [0.99131966],\n",
       "       [0.9968935 ],\n",
       "       [0.9965652 ],\n",
       "       [0.99250495],\n",
       "       [0.9975064 ],\n",
       "       [0.99864256],\n",
       "       [0.997233  ],\n",
       "       [0.99881744],\n",
       "       [0.9991419 ],\n",
       "       [0.9961647 ],\n",
       "       [0.9921694 ],\n",
       "       [0.9968649 ],\n",
       "       [0.99719954],\n",
       "       [0.9974492 ],\n",
       "       [0.9992647 ],\n",
       "       [0.9968764 ],\n",
       "       [0.9902038 ],\n",
       "       [0.9989853 ],\n",
       "       [0.99704313],\n",
       "       [0.99941385],\n",
       "       [0.9992721 ],\n",
       "       [0.99642867],\n",
       "       [0.99554616],\n",
       "       [0.99807084],\n",
       "       [0.9985764 ],\n",
       "       [0.9992912 ],\n",
       "       [0.996014  ],\n",
       "       [0.98771447],\n",
       "       [0.9961934 ],\n",
       "       [0.99865997],\n",
       "       [0.99807745],\n",
       "       [0.99776137],\n",
       "       [0.99830395],\n",
       "       [0.99851453],\n",
       "       [0.9988067 ],\n",
       "       [0.9992257 ],\n",
       "       [0.99976367],\n",
       "       [0.99449205],\n",
       "       [0.99926096],\n",
       "       [0.9995002 ],\n",
       "       [0.9995934 ],\n",
       "       [0.99632245],\n",
       "       [0.9985298 ],\n",
       "       [0.993382  ],\n",
       "       [0.99335396],\n",
       "       [0.9875797 ],\n",
       "       [0.9980507 ],\n",
       "       [0.99873555],\n",
       "       [0.9986905 ],\n",
       "       [0.9957907 ],\n",
       "       [0.9990833 ],\n",
       "       [0.9922316 ],\n",
       "       [0.99636227],\n",
       "       [0.99337995],\n",
       "       [0.9953221 ],\n",
       "       [0.9975283 ],\n",
       "       [0.9918095 ],\n",
       "       [0.996719  ],\n",
       "       [0.99487734],\n",
       "       [0.9954952 ],\n",
       "       [0.99896073],\n",
       "       [0.999365  ],\n",
       "       [0.99741423],\n",
       "       [0.99603313],\n",
       "       [0.998564  ],\n",
       "       [0.9983844 ],\n",
       "       [0.9964218 ],\n",
       "       [0.99605644],\n",
       "       [0.9863997 ],\n",
       "       [0.9957183 ],\n",
       "       [0.98818743],\n",
       "       [0.9933501 ],\n",
       "       [0.999328  ],\n",
       "       [0.98092985],\n",
       "       [0.9844421 ],\n",
       "       [0.99606985],\n",
       "       [0.99818075],\n",
       "       [0.99894786],\n",
       "       [0.9965986 ],\n",
       "       [0.9983682 ],\n",
       "       [0.9937487 ],\n",
       "       [0.99585944],\n",
       "       [0.9993669 ],\n",
       "       [0.99856347],\n",
       "       [0.9984793 ],\n",
       "       [0.9936843 ],\n",
       "       [0.9976211 ],\n",
       "       [0.9984724 ],\n",
       "       [0.9979596 ],\n",
       "       [0.99728227],\n",
       "       [0.99968606],\n",
       "       [0.9963584 ],\n",
       "       [0.99644566],\n",
       "       [0.9977288 ],\n",
       "       [0.98631954],\n",
       "       [0.99965423],\n",
       "       [0.9993181 ],\n",
       "       [0.99474144],\n",
       "       [0.99925697],\n",
       "       [0.98964727],\n",
       "       [0.9984951 ],\n",
       "       [0.99572825],\n",
       "       [0.98536366],\n",
       "       [0.9937597 ],\n",
       "       [0.9993921 ],\n",
       "       [0.9847654 ],\n",
       "       [0.99266243],\n",
       "       [0.98890984],\n",
       "       [0.98354495],\n",
       "       [0.9967827 ],\n",
       "       [0.99743354],\n",
       "       [0.9941141 ],\n",
       "       [0.9865892 ],\n",
       "       [0.99508107],\n",
       "       [0.9990195 ],\n",
       "       [0.9951189 ],\n",
       "       [0.9986652 ],\n",
       "       [0.9907317 ],\n",
       "       [0.99715996],\n",
       "       [0.9939054 ],\n",
       "       [0.99845624],\n",
       "       [0.99833375],\n",
       "       [0.9946476 ],\n",
       "       [0.9968955 ],\n",
       "       [0.9959806 ],\n",
       "       [0.9991648 ],\n",
       "       [0.99694854],\n",
       "       [0.9994725 ],\n",
       "       [0.9984324 ],\n",
       "       [0.99950296],\n",
       "       [0.99572897],\n",
       "       [0.9939413 ],\n",
       "       [0.9960822 ],\n",
       "       [0.9993142 ],\n",
       "       [0.99933517],\n",
       "       [0.998679  ],\n",
       "       [0.999424  ],\n",
       "       [0.99847686],\n",
       "       [0.9968752 ],\n",
       "       [0.99917054],\n",
       "       [0.9981028 ],\n",
       "       [0.99818826],\n",
       "       [0.9990901 ],\n",
       "       [0.990311  ],\n",
       "       [0.99160546],\n",
       "       [0.99043965],\n",
       "       [0.994369  ],\n",
       "       [0.99593717],\n",
       "       [0.98110485],\n",
       "       [0.9980803 ],\n",
       "       [0.9986316 ],\n",
       "       [0.9983956 ],\n",
       "       [0.99783444],\n",
       "       [0.9990776 ],\n",
       "       [0.9927226 ],\n",
       "       [0.9876883 ],\n",
       "       [0.99925095],\n",
       "       [0.9993905 ],\n",
       "       [0.99976337],\n",
       "       [0.9992794 ],\n",
       "       [0.99518746],\n",
       "       [0.9981483 ],\n",
       "       [0.99653435],\n",
       "       [0.98464656],\n",
       "       [0.9982579 ],\n",
       "       [0.99780834],\n",
       "       [0.9990614 ],\n",
       "       [0.98568994],\n",
       "       [0.9918829 ],\n",
       "       [0.98283184],\n",
       "       [0.98966825],\n",
       "       [0.9975337 ],\n",
       "       [0.9986921 ],\n",
       "       [0.9985186 ],\n",
       "       [0.9992956 ],\n",
       "       [0.9988339 ],\n",
       "       [0.99935806],\n",
       "       [0.99711967],\n",
       "       [0.9982792 ],\n",
       "       [0.991691  ],\n",
       "       [0.9972678 ],\n",
       "       [0.99780875],\n",
       "       [0.9986086 ],\n",
       "       [0.9992733 ],\n",
       "       [0.9988003 ],\n",
       "       [0.997314  ],\n",
       "       [0.99940664],\n",
       "       [0.99617326],\n",
       "       [0.99723125],\n",
       "       [0.9933715 ],\n",
       "       [0.99600804],\n",
       "       [0.99954754],\n",
       "       [0.9857077 ],\n",
       "       [0.9877709 ],\n",
       "       [0.988929  ],\n",
       "       [0.9990381 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
